# Papers
## GANs
  1. GAN: https://arxiv.org/pdf/1406.2661.pdf
  1. DCGAN: https://arxiv.org/pdf/1511.06434.pdf
  1. WGAN: https://arxiv.org/pdf/1701.07875.pdf
  1. GP: https://arxiv.org/pdf/1910.06922.pdf
  1. Pix2Pix: https://arxiv.org/pdf/1611.07004.pdf
  1. CycleGAN: https://arxiv.org/pdf/1703.10593.pdf
  1. ProGAN: https://arxiv.org/pdf/1710.10196v3.pdf
  1. SRGAN: https://arxiv.org/pdf/1609.04802.pdf
  1. ESRGAN: https://arxiv.org/pdf/1809.00219.pdf
  1. StyleGAN: https://arxiv.org/pdf/1812.04948.pdf
  1. StyleGAN2: https://arxiv.org/pdf/1912.04958.pdf
  1. StyleGAN3: https://arxiv.org/pdf/2201.13433.pdf
  1. StyleGAN1.T: https://arxiv.org/pdf/2301.09515.pdf
  1. GauGAN: https://arxiv.org/pdf/1903.07291.pdf

## Image Segmentation
  1. UNet: https://arxiv.org/pdf/1505.04597

## Image Recognition
  1. ResNet: https://arxiv.org/pdf/1512.03385.pdf
  1. VGG: https://arxiv.org/pdf/1409.1556.pdf
  1. GoogleNet (InceptionV1): https://arxiv.org/pdf/1409.4842.pdf
  1. LeNet: https://arxiv.org/pdf/1609.04112.pdf
  1. AlexNet: https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
  1. EfficientNetV1: https://arxiv.org/pdf/1905.11946.pdf
  1. MobileNet: https://arxiv.org/pdf/1704.04861.pdf
  1. SENet: https://arxiv.org/pdf/1611.05431.pdf
  1. ResNeXt: https://arxiv.org/pdf/1611.05431.pdf
  1. YOLOv1 (You Only Look Once): https://arxiv.org/pdf/1506.02640.pdf
  1. YOLOv2: https://arxiv.org/pdf/1612.08242.pdf
  1. YOLOv3: https://arxiv.org/pdf/1804.02767.pdf
  1. YOLOv5
  1. YOLOv6
  1. YOLOv7
  1. YOLOv8

## Models
  1. BERT:
  1. Diffusion:
  1. Tranformers:
  1. Attention
  1. Whisper
