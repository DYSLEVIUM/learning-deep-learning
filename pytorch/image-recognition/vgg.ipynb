{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from functools import partial\nfrom typing import Any, cast, Dict, List, Optional, Union\n\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-08-27T10:22:15.470300Z","iopub.execute_input":"2023-08-27T10:22:15.470675Z","iopub.status.idle":"2023-08-27T10:22:15.476577Z","shell.execute_reply.started":"2023-08-27T10:22:15.470644Z","shell.execute_reply":"2023-08-27T10:22:15.475207Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class VGG(nn.Module):\n    def __init__(\n        self, features: nn.Module, in_channels: int = 3, num_classes: int = 1000, init_weights: bool = True, dropout: float = 0.5\n    ) -> None:\n        super().__init__()\n        self.features = features\n        self.in_channels = in_channels\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(p=dropout),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(p=dropout),\n            nn.Linear(4096, num_classes),\n        )\n        if init_weights:\n            for m in self.modules():\n                if isinstance(m, nn.Conv2d):\n                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n                    if m.bias is not None:\n                        nn.init.constant_(m.bias, 0)\n                elif isinstance(m, nn.BatchNorm2d):\n                    nn.init.constant_(m.weight, 1)\n                    nn.init.constant_(m.bias, 0)\n                elif isinstance(m, nn.Linear):\n                    nn.init.normal_(m.weight, 0, 0.01)\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n\ndef make_layers(cfg: List[Union[str, int]], in_channels: int = 3, batch_norm: bool = False) -> nn.Sequential:\n    layers: List[nn.Module] = []\n    for v in cfg:\n        if v == \"M\":\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            v = cast(int, v)\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            layers += [conv2d]\n            if batch_norm:\n                layers += [nn.BatchNorm2d(v)]\n            layers += [nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-27T10:22:15.482259Z","iopub.execute_input":"2023-08-27T10:22:15.483328Z","iopub.status.idle":"2023-08-27T10:22:15.500303Z","shell.execute_reply.started":"2023-08-27T10:22:15.483289Z","shell.execute_reply":"2023-08-27T10:22:15.499334Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"cfgs: Dict[str, List[Union[str, int]]] = {\n    \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"], # VGG11\n    \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"], #VGG13\n    \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"], #VGG16\n    \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"], #VGG19\n}\n\n\ndef _vgg(cfg: str, batch_norm: bool, weights: Optional[WeightsEnum], progress: bool, **kwargs: Any) -> VGG:\n#     if weights is not None:\n#         kwargs[\"init_weights\"] = False\n#         if weights.meta[\"categories\"] is not None:\n#             _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n#     if weights is not None:\n#         model.load_state_dict(weights.get_state_dict(progress=progress, check_hash=True))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-27T10:22:15.501824Z","iopub.execute_input":"2023-08-27T10:22:15.502736Z","iopub.status.idle":"2023-08-27T10:22:15.519515Z","shell.execute_reply.started":"2023-08-27T10:22:15.502700Z","shell.execute_reply":"2023-08-27T10:22:15.518460Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# def vgg16(*, weights: Optional[VGG16_Weights] = None, progress: bool = True, in_channels: int = 3, **kwargs: Any) -> VGG:\ndef vgg16(*, weights = None, progress: bool = True, in_channels: int = 3, **kwargs: Any) -> VGG:\n    \"\"\"VGG-16 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n\n    Args:\n        weights (:class:`~torchvision.models.VGG16_Weights`, optional): The\n            pretrained weights to use. See\n            :class:`~torchvision.models.VGG16_Weights` below for\n            more details, and possible values. By default, no pre-trained\n            weights are used.\n        progress (bool, optional): If True, displays a progress bar of the\n            download to stderr. Default is True.\n        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n            base class. Please refer to the `source code\n            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n            for more details about this class.\n\n    .. autoclass:: torchvision.models.VGG16_Weights\n        :members:\n    \"\"\"\n#     weights = VGG16_Weights.verify(weights)\n    weights = None\n\n    return _vgg(\"D\", in_channels, False, weights, progress, **kwargs)\n\n\n# def vgg16_bn(*, weights: Optional[VGG16_BN_Weights] = None, progress: bool = True, **kwargs: Any) -> VGG:\ndef vgg16_bn(*, weights = None, progress: bool = True, **kwargs: Any) -> VGG:\n    \"\"\"VGG-16-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\n\n    Args:\n        weights (:class:`~torchvision.models.VGG16_BN_Weights`, optional): The\n            pretrained weights to use. See\n            :class:`~torchvision.models.VGG16_BN_Weights` below for\n            more details, and possible values. By default, no pre-trained\n            weights are used.\n        progress (bool, optional): If True, displays a progress bar of the\n            download to stderr. Default is True.\n        **kwargs: parameters passed to the ``torchvision.models.vgg.VGG``\n            base class. Please refer to the `source code\n            <https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py>`_\n            for more details about this class.\n\n    .. autoclass:: torchvision.models.VGG16_BN_Weights\n        :members:\n    \"\"\"\n#     weights = VGG16_BN_Weights.verify(weights)\n    weights = None\n\n    return _vgg(\"D\", True, weights, progress, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T10:22:15.521583Z","iopub.execute_input":"2023-08-27T10:22:15.522217Z","iopub.status.idle":"2023-08-27T10:22:15.540115Z","shell.execute_reply.started":"2023-08-27T10:22:15.522181Z","shell.execute_reply":"2023-08-27T10:22:15.538581Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def test():\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    img_chan = 3\n    \n    x = torch.randn(2, img_chan, 256, 256)\n\n    model = vgg16_bn(in_channels = img_chan)\n    \n    y = model(x).to(DEVICE)\n    \n    print(y)\n    print(y.shape)\n    \ntest()","metadata":{"execution":{"iopub.status.busy":"2023-08-27T10:22:15.541725Z","iopub.execute_input":"2023-08-27T10:22:15.542637Z","iopub.status.idle":"2023-08-27T10:22:19.621798Z","shell.execute_reply.started":"2023-08-27T10:22:15.542582Z","shell.execute_reply":"2023-08-27T10:22:19.620703Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"tensor([[ 0.6072, -0.0852,  0.1112,  ...,  0.1085, -0.1509,  0.6420],\n        [ 1.2399,  0.3745, -0.3755,  ..., -1.0668,  0.3487,  0.3252]],\n       grad_fn=<AddmmBackward0>)\ntorch.Size([2, 1000])\n","output_type":"stream"}]}]}