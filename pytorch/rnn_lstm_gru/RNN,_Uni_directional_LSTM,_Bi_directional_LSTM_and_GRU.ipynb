{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df5e91da99bd43acb2cedf21af1bde1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_720e041231cd4e79b682c135d1bb78c3",
              "IPY_MODEL_a97789ef817241feafeac8a3281e7abd",
              "IPY_MODEL_1ffd5e403db64bba9b3ea5040ea7d2c2"
            ],
            "layout": "IPY_MODEL_94e98a25c585459685d2cfbcbf48d1ac"
          }
        },
        "720e041231cd4e79b682c135d1bb78c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70f092d554b54c54bd224a71050ad280",
            "placeholder": "​",
            "style": "IPY_MODEL_31bfc8a3672043fbb655627e631e963b",
            "value": "  0%"
          }
        },
        "a97789ef817241feafeac8a3281e7abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b799ff0f4a4a448b8f77a46129fa03ed",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8238c7ca39274b73a301e4faa5c3309f",
            "value": 0
          }
        },
        "1ffd5e403db64bba9b3ea5040ea7d2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad14b8ed4824575aa50ac984fb469fb",
            "placeholder": "​",
            "style": "IPY_MODEL_43da76039d3b4e10888cea42c1db570d",
            "value": " 0/16 [00:24&lt;?, ?it/s]"
          }
        },
        "94e98a25c585459685d2cfbcbf48d1ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f092d554b54c54bd224a71050ad280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bfc8a3672043fbb655627e631e963b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b799ff0f4a4a448b8f77a46129fa03ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8238c7ca39274b73a301e4faa5c3309f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cad14b8ed4824575aa50ac984fb469fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43da76039d3b4e10888cea42c1db570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hlub7ZkZoRX",
        "outputId": "70e016c4-6fa3-4a56-e5b0-4d83519ee8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (0.14.1)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.8/dist-packages (0.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
            "Requirement already satisfied: watermark in /usr/local/lib/python3.8/dist-packages (2.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext) (2.25.1)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.26.14)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.10.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from watermark) (7.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (5.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.18.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->watermark) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchtext torchdata tqdm torchinfo numpy pandas matplotlib seaborn watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%reload_ext watermark"
      ],
      "metadata": {
        "id": "OeNtzUSzb_pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4fcb04-f492-4597-c094-a586e74533ba"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%watermark -a 'Pushpakant Behera' -h -m -v -p torch,torchtext,torchdata,numpy,pandas,matplotlib,seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3cKOMJkbNh_",
        "outputId": "427b9f10-b1f7-49ee-c6c4-06c37b69c18c"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Pushpakant Behera\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.8.10\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "torch     : 1.13.1+cu116\n",
            "torchtext : 0.14.1\n",
            "torchdata : 0.5.1\n",
            "numpy     : 1.22.4\n",
            "pandas    : 1.3.5\n",
            "matplotlib: 3.5.3\n",
            "seaborn   : 0.11.2\n",
            "\n",
            "Compiler    : GCC 9.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.10.147+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "Hostname: bd6d9dacda51\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from torchinfo import summary\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "YnD4DOn0d06A"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "3VquI5C7eu39"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_trainset, imdb_testset = IMDB(root='.', split=('train', 'test')) # iterable dataset"
      ],
      "metadata": {
        "id": "Kw93HhaJgUym"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for idx, (label, line) in enumerate(imdb_trainset):\n",
        "    if label != 1:\n",
        "        print(label, line)\n",
        "        cnt = cnt + 1\n",
        "\n",
        "    if cnt == 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPsnF17zq4dm",
        "outputId": "a7d55e08-0af4-4104-9e28-e835d4f5c423"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn't really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I'd have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.\n",
            "2 Zentropa is the most original movie I've seen in years. If you like unique thrillers that are influenced by film noir, then this is just the right cure for all of those Hollywood summer blockbusters clogging the theaters these days. Von Trier's follow-ups like Breaking the Waves have gotten more acclaim, but this is really his best work. It is flashy without being distracting and offers the perfect combination of suspense and dark humor. It's too bad he decided handheld cameras were the wave of the future. It's hard to say who talked him away from the style he exhibits here, but it's everyone's loss that he went into his heavily theoretical dogma direction instead.\n",
            "2 Lars Von Trier is never backward in trying out new techniques. Some of them are very original while others are best forgotten.<br /><br />He depicts postwar Germany as a nightmarish train journey. With so many cities lying in ruins, Leo Kessler a young American of German descent feels obliged to help in their restoration. It is not a simple task as he quickly finds out.<br /><br />His uncle finds him a job as a night conductor on the Zentropa Railway Line. His job is to attend to the needs of the passengers. When the shoes are polished a chalk mark is made on the soles. A terrible argument ensues when a passenger's shoes are not chalked despite the fact they have been polished. There are many allusions to the German fanaticism of adherence to such stupid details.<br /><br />The railway journey is like an allegory representing man's procession through life with all its trials and tribulations. In one sequence Leo dashes through the back carriages to discover them filled with half-starved bodies appearing to have just escaped from Auschwitz . These images, horrible as they are, are fleeting as in a dream, each with its own terrible impact yet unconnected.<br /><br />At a station called Urmitz Leo jumps from the train with a parceled bomb. In view of many by-standers he connects the bomb to the underside of a carriage. He returns to his cabin and makes a connection to a time clock. Later he jumps from the train (at high speed) and lies in the cool grass on a river bank. Looking at the stars above he decides that his job is to build and not destroy. Subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock. If you care to analyse the situation it is a completely impossible task. Quite ridiculous in fact. It could only happen in a dream.<br /><br />It's strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train.<br /><br />Despite the fact that this film is widely acclaimed, I prefer Lars Von Trier's later films (Breaking the Waves and The Idiots). The bomb scene described above really put me off. Perhaps I'm a realist.\n",
            "2 *Contains spoilers due to me having to describe some film techniques, so read at your own risk!*<br /><br />I loved this film. The use of tinting in some of the scenes makes it seem like an old photograph come to life. I also enjoyed the projection of people on a back screen. For instance, in one scene, Leopold calls his wife and she is projected behind him rather than in a typical split screen. Her face is huge in the back and Leo's is in the foreground.<br /><br />One of the best uses of this is when the young boys kill the Ravensteins on the train, a scene shot in an almost political poster style, with facial close ups. It reminded me of Battleship Potemkin, that intense constant style coupled with the spray of red to convey tons of horror without much gore. Same with the scene when Katharina finds her father dead in the bathtub...you can only see the red water on the side. It is one of the things I love about Von Trier, his understatement of horror, which ends up making it all the more creepy.<br /><br />The use of text in the film was unique, like when Leo's character is pushed by the word, \"Werewolf.\" I have never seen anything like that in a film.<br /><br />The use of black comedy in this film was well done. Ernst-Hugo Järegård is great as Leo's uncle. It brings up the snickers I got from his role in the Kingdom (Riget.) This humor makes the plotline of absurd anal retentiveness of train conductors against the terrible backdrop of WW2 and all the chaos, easier to take. It reminds me of Riget in the way the hospital administrator is trying to maintain a normalcy at the end of part one when everything is going crazy. It shows that some people are truly oblivious to the awful things happening around them. Yet some people, like Leo, are tuned in, but do nothing positive about it.<br /><br />The voice over, done expertly well by Max von Sydow, is amusing too. It draws you into the story and makes you jump into Leo's head, which at times is a scary place to be.<br /><br />The movie brings up the point that one is a coward if they don't choose a side. I see the same idea used in Dancer in the Dark, where Bjork's character doesn't speak up for herself and ends up being her own destruction. Actually, at one time, Von Trier seemed anti-woman to me, by making Breaking the Waves and Dancer, but now I know his male characters don't fare well either! I found myself at the same place during the end of Dancer, when you seriously want the main character to rethink their actions, but of course, they never do!\n",
            "2 That was the first thing that sprang to mind as I watched the closing credits to Europa make there was across the screen, never in my entire life have I seen a film of such technical genius, the visuals of Europa are so impressive that any film I watch in it's wake will only pale in comparison, forget your Michael Bay, Ridley Scott slick Hollywood cinematography, Europa has more ethereal beauty than anything those two could conjure up in a million years. Now I'd be the first to hail Lars von Trier a genius just off the back of his films Breaking the Waves and Dancer in the Dark, but this is stupid, the fact that Europa has gone un-noticed by film experts for so long is a crime against cinema, whilst overrated rubbish like Crouching Tiger, Hidden Dragon and Life is Beautiful clean up at the academy awards (but what do the know) Europa has been hidden away, absent form video stores and (until recently) any British TV channels. <br /><br />The visuals in Europa are not MTV gloss; it's not a case of style over substance, its more a case of substance dictating style. Much like his first film The Element of Crime, von Trier uses the perspective of the main character to draw us into his world, and much like Element, the film begins with the main character (or in the case of Europa, we the audience) being hypnotized. As we move down the tracks, the voice of the Narrator (Max von Sydow) counts us down into a deep sleep, until we awake in Europa. This allows von Trier and his three cinematographers to pay with the conventions of time and imagery, there are many scenes in Europa when a character in the background, who is in black and white, will interact with a person in the foreground who will be colour, von Trier is trying to show us how much precedence the coloured item or person has over the plot, for instance, it's no surprise that the first shot of Leopold Kessler (Jean-marc Barr) is in colour, since he is the only character who's actions have superiority over the film. <br /><br />The performances are good, they may not be on par with performances in later von Trier films, but that's just because the images are sometimes so distracting that you don't really pick up on them the first time round. But I would like to point out the fantastic performance of Jean-Marc Barr in the lead role, whose blind idealism is slowly warn down by the two opposing sides, until he erupts in the films final act. Again, muck like The Element of Crime, the film ends with our hero unable to wake up from his nightmare state, left in this terrible place, with only the continuing narration of von Sydow to seal his fate. Europa is a tremendous film, and I cant help thinking what a shame that von Trier has abandoned this way of filming, since he was clearly one of the most talented visual directors working at that time, Europa, much like the rest of his cinematic cannon is filled with a wealth of iconic scenes. His dedication to composition and mise-en-scene is unrivalled, not to mention his use of sound and production design. But since his no-frills melodramas turned out to be Breaking the Waves and Dancer in the Dark then who can argue, but it does seems like a waste of an imaginative talent. 10/10\n",
            "2 I had started to lose my faith in films of recent being inundated with the typical Genre Hollywood film. Story lines fail, and camera work is merely copied from the last film of similiar taste. But, then I saw Zentropa (Europa) and my faith was renewed. Not only is the metaphorical storyline enthralling but the use of color and black and white is visually stimulating. The narrator (Max Von Sydow) takes you through a spellbounding journey every step of the way and engrosses you into Europa 1945. We have all seen death put on screen in a hundred thousand ways but the beauty of this film is how it takes you through every slow-moving moment that leads you to death. Unlike many films it doesn't cut after one second of showing (for example) a knife but forces you to watch the devastating yet sensuous beauty of a man's final moments. I think we can all take something different away from what this movie is trying to say but it is definitely worth taking the time to find out what it all really means. I would love to talk more in depth about the film for any one who wishes to send me an email. Enjoy it!\n",
            "2 Critics need to review what they class as a quality movie. I think the critics have seen too many actions films and have succumbed to the Matrix style of films. Europa is a breath of fresh air, a film with so many layers that one viewing is not enough to understand or appreciate this outstanding film. Lars von Trier shows that old styles of filming can produce marvellous cinema and build drama and tension. The back projection effect he uses during the film arouses and enhances the characters, and the focus of the conversation they are having. Other effects he uses such as the colour and black and white in one scene much like Hitchcock and the girl with the red coat grabs attention and enhances the drama and meaning of the scene. The commentary is superb and has a hypnotic effect, again maintaining the focus on the central characters in the scene and there actions.<br /><br />I could talk about the effects more but I think you all would agree they push this film into a category of its own, and really heighten the drama of the film. A film to buy if you don't own already and one to see if you have not.<br /><br />10/10 Don't miss this artistic noir film from one of the great film directors.\n",
            "2 It is not every film's job to stimulate you superficially. I will take an ambitious failure over a mass-market hit any day. While this really can't be described as a failure, the sum of its parts remains ambiguous. That indecipherable quality tantalizes me into watching it again and again. This is a challenging, provocative movie that does not wrap things up neatly. The problem with the movie is in its structure. Its inpenetrable plot seems to be winding up, just as a second ending is tacked on. Though everything is technically dazzling, the movie is exactly too long by that unit. The long-delayed climax of Leo's awakening comes about 20 minutes late.<br /><br />Great cinematography often comes at the expense of a decent script, but here the innovative camera technique offers a wealth of visual ideas. The compositing artifice is provocative and engaging; A character is rear-projected but his own hand in the foreground isn't. The world depicted is deliberate, treacherous and absurd. Keep your eyes peeled for a memorable, technically astonishing assassination that will make your jaw drop.<br /><br />The compositions are stunning. Whomever chose to release the (out of print) videotape in the pan & scan format must have never seen it. Where is the DVD?<br /><br />It is unfathomable how anyone could give this much originality a bad review. You should see it at least once. You get the sense that von Trier bit off more than he could chew, but this movie ends up being richer for it. I suspect he is familiar with Hitchcock's Foreign Correspondent in which devious Europeans also manipulate an American dupe and several Welles movies that take delirious joy in technique as much as he does. All von Trier movies explore the plight of the naif amidst unforgiving societies. After Zentropa, von Trier moved away from this type of audacious technical experiment towards dreary, over-rated, un-nuanced sap like Breaking the Waves and Dancer in the Dark.\n",
            "2 The best way for me to describe Europa, which is high on the list of my favourite films, is the exclamation that came from a companion after the film ended: \"I didn't know films could be made like that\". Entirely original in it's visual style, it is one of the best examples of what cinema can be. It's as far away from the \"master and coverage\" style of shooting as one can get; perfectly integrating many layers of image, sound, effects, props, dialogue, voice over, performance, editing, lighting, etc... all equal, none predominant. Despite Hollywood's \"dialogue\" myopia, cinema is not about dialogue, nor is it about beautiful lighting, action or music. It works best when all the elements are on an equal footing, where ONLY the BLENDING of those elements, in the order or combination in which they are presented, will communicate the idea. Reduce or eliminate the contribution of one element, and the film has no meaning. \"Europa\" is what cinema should strive to be.\n",
            "2 Released as Zentropa in North America to avoid confusion with Agniezska Holland's own Holocaust film Europa Europa, this third theatrical feature by a filmmaker who never ceases to surprise, inspire or downright shock is a bizarre, nostalgic, elaborate film about a naive American in Germany shortly following the end of WWII. The American, named Leo, doesn't fully get what he's doing there. He has come to take part in fixing up the country since, in his mind, it's about time Germany was shown some charity. No matter how that sounds, he is not a Nazi sympathizer or so much as especially pro-German, merely mixed up. His uncle, who works on the railroad, gets Leo a job as a helmsman on a sleeping car, and he is increasingly enmeshed in a vortex of 1945 Germany's horrors and enigmas.<br /><br />This progression starts when Leo, played rather memorably by the calm yet restless actor Jean-Marc Barr, meets a sultry heiress on the train played by Barbara Sukowa, an actress with gentility on the surface but internal vigor. She seduces him and then takes him home to meet her family, which owns the company which manufactures the trains. These were the precise trains that took Jews to their deaths during the war, but now they run a drab day-to-day timetable, and the woman's Uncle Kessler postures as another one of those good Germans who were just doing their jobs. There is also Udo Kier, the tremendous actor who blew me away in Von Trier's shocking second film Epidemic, though here he is mere scenery.<br /><br />Another guest at the house is Eddie Constantine, an actor with a quiet strength, playing a somber American intelligence man. He can confirm that Uncle Kessler was a war criminal, though it is all completely baffling to Leo. Americans have been characterized as gullible rubes out of their element for decades, but little have they been more blithely unconcerned than Leo, who goes back to his job on what gradually looks like his own customized death train.<br /><br />The story is told in a purposely uncoordinated manner by the film's Danish director, Lars Von Trier, whose anchor is in the film's breathtaking editing and cinematography. He shoots in black and white and color, he uses double-exposures, optical effects and trick photography, having actors interact with rear-projected footage, he places his characters inside a richly shaded visceral world so that they sometimes feel like insects, caught between glass for our more precise survey.<br /><br />This Grand Jury Prize-winning surrealist work is allegorical, but maybe in a distinct tone for every viewer. I interpret it as a film about the last legs of Nazism, symbolized by the train, and the ethical accountability of Americans and others who appeared too late to salvage the martyrs of these trains and the camps where they distributed their condemned shiploads. During the time frame of the movie, and the Nazi state, and such significance to the train, are dead, but like decapitated chickens they persist in jolting through their reflexes.<br /><br />The characters, music, dialogue, and plot are deliberately hammy and almost satirically procured from film noir conventions. The most entrancing points in the movie are the entirely cinematographic ones. Two trains halting back and forth, Barr on one and Sukowa on another. An underwater shot of proliferating blood. An uncommonly expressive sequence on what it must be like to drown. And most metaphysically affecting of all, an anesthetic shot of train tracks, as Max von Sydow's voice allures us to hark back to Europe with him, and abandon our personal restraint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesing\n",
        "\n",
        "'''\n",
        "    Here is an example for typical NLP data processing with tokenizer and vocabulary.\n",
        "    The first step is to build a vocabulary with the raw training dataset.\n",
        "    Here we use built in factory function build_vocab_from_iterator which accepts iterator that yield list or iterator of tokens.\n",
        "    Users can also pass any special symbols to be added to the vocabulary.\n",
        "'''\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "# tokenizer = get_tokenizer('spacy')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "token_generator = yield_tokens(imdb_trainset)\n",
        "\n",
        "vocab = build_vocab_from_iterator(token_generator, specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "LEeK42Sfqe1V"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab.get_itos()[:10])"
      ],
      "metadata": {
        "id": "Y7FP3YkszwtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f567cdd7-c329-4be7-a909-7938c4d51bb3"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\", 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(vocab.get_stoi().keys())[:10])\n",
        "print(list(vocab.get_stoi().values())[:10])"
      ],
      "metadata": {
        "id": "fws8BSdp0B3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ccc3e8-6518-41ee-e8d2-48f481e917d7"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['₤250', '₤100', '“you’ve', '“x”', '“sanatorium”', '“playboy”', '“mr', '“jean', '“it’s', '“him”']\n",
            "[100682, 100681, 100679, 100678, 100677, 100676, 100673, 100670, 100668, 100667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The vocabulary block converts a list of tokens into integers. For example,\n",
        "print(vocab(['here', 'is', 'an', 'example', 'I']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTGMN1uOtbnS",
        "outputId": "2c514600-e840-470b-e4b1-44ae939ed3eb"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[131, 9, 40, 464, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Prepare the text processing pipeline with the tokenizer and vocabulary.\n",
        "The text and label pipelines will be used to process the raw data strings from the dataset iterators.\n",
        "'''\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "metadata": {
        "id": "fUJuq1KQtctz"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The text pipeline converts a text string into a list of integers based on the lookup table defined in the vocabulary.\n",
        "The label pipeline converts the label into integers. For example,\n",
        "'''\n",
        "print(text_pipeline('here is the an example'))\n",
        "print(label_pipeline('10'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvgB1RZWteX-",
        "outputId": "d1c068a7-053f-4afa-acb9-6bf7adc79548"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[131, 9, 1, 40, 464]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 3e-4\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 16\n",
        "\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 16\n",
        "\n",
        "# NUM_CLASSES = len(set([label for (label, text) in imdb_trainset]))\n",
        "NUM_CLASSES = 1\n",
        "VOCABULARY_SIZE = len(vocab)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jNHJxMMPsC_P"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    torch.utils.data.DataLoader is recommended for PyTorch users.\n",
        "    It works with a map-style dataset that implements the getitem() and len() protocols, and represents a map from indices/keys to data samples.\n",
        "    It also works with an iterable dataset with the shuffle argument of False.\n",
        "\n",
        "    Before sending to the model, collate_fn function works on a batch of samples generated from DataLoader.\n",
        "    The input to collate_fn is a batch of data with the batch size in DataLoader, and collate_fn processes them according to the data processing pipelines declared previously.\n",
        "    Pay attention here and make sure that collate_fn is declared as a top level def.\n",
        "    This ensures that the function is available in each worker.\n",
        "\n",
        "    In this example, the text entries in the original data batch input are packed into a list and concatenated as a single tensor for the input of nn.EmbeddingBag.\n",
        "    The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor.\n",
        "    Label is a tensor saving the labels of individual text entries.\n",
        "'''\n",
        "\n",
        "'''\n",
        "    The offsets list in the collate_batch function is used to keep track of the starting indices of each text sample in the batch, \n",
        "        so that the word indices of each sample can be properly aligned when they are concatenated into a single tensor.\n",
        "    In more detail, during the loop over the samples in the batch, the processed_text tensor is created for each sample, \n",
        "        which contains the word indices of the tokenized text. The length of this tensor corresponds to the number of tokens in the text.\n",
        "    The offsets list is then updated to include the cumulative sum of the lengths of all the previous tensors, \n",
        "        so that the value at each index of the offsets list represents the starting index of the corresponding text sample in the concatenated tensor.\n",
        "    For example, suppose we have a batch of two text samples, where the first sample has 10 tokens and the second sample has 8 tokens.\n",
        "    When the processed_text tensor is created for the first sample, its length is 10, so the current value of the offsets list is [0].\n",
        "    When the processed_text tensor is created for the second sample, its length is 8, so the offsets list is updated to [0, 10], \n",
        "        since the second sample starts at index 10 in the concatenated tensor.\n",
        "    These offsets are later used to split the concatenated tensor into individual text samples during the forward pass of the model,\n",
        "        so that each sample is processed independently and the output of the model corresponds to the correct sample in the batch.\n",
        "'''\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(DEVICE), text_list.to(DEVICE), offsets.to(DEVICE)\n",
        "\n",
        "train_loader = DataLoader(imdb_trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)\n",
        "test_loader = DataLoader(imdb_testset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch, drop_last=False)"
      ],
      "metadata": {
        "id": "vjD6ojPVqG8V"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BoW (Bag of Words) model\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        '''\n",
        "        The model is composed of the nn.EmbeddingBag layer plus a linear layer for the classification purpose.\n",
        "        nn.EmbeddingBag with the default mode of “mean” computes the mean value of a “bag” of embeddings.\n",
        "        Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n",
        "        Additionally, since nn.EmbeddingBag accumulates the average across the embeddings on the fly,\n",
        "            nn.EmbeddingBag can enhance the performance and memory efficiency to process a sequence of tensors.\n",
        "        '''\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 5e-1\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "id": "wmOpC0FbttNG"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, embedding_dim, num_classes, num_layers):\n",
        "        super().__init__()\n",
        " \n",
        "        self.output_dim = num_classes\n",
        "        self.hidden_dim = hidden_dim\n",
        " \n",
        "        self.no_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "    \n",
        "        # embedding and RNN layers\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=self.hidden_dim,\n",
        "                           num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(self.hidden_dim, num_classes)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        # initialize hidden state\n",
        "        hidden = self.init_hidden()\n",
        "\n",
        "        # embed the input\n",
        "        embedded = self.embedding(text, offsets)\n",
        "\n",
        "        # pass through the RNN layer\n",
        "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
        "        rnn_out = rnn_out.contiguous().view(-1, self.hidden_dim) \n",
        "\n",
        "        # apply dropout\n",
        "        out = self.dropout(rnn_out)\n",
        "\n",
        "        # pass through the linear layer\n",
        "        out = self.fc(out).squeeze() # squeeze as it is binary classification\n",
        "\n",
        "        # apply sigmoid activation\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        return sig_out\n",
        "\n",
        "    '''\n",
        "        Why do we need to init_hidden every epoch? Shouldn't it be that the model inherit the hidden parameters from last epoch and continue training on them.\n",
        "        >   The answer lies in init_hidden. It is not the hidden layer weights but the initial hidden state in RNN/LSTM, which is h0 in the formulas.\n",
        "            For every epoch, we should re-initialize a new beginner hidden state, this is because during the testing,\n",
        "            our model will have no information about the test sentence and will have a zero initial hidden state.\n",
        "    '''\n",
        "    def init_hidden(self):\n",
        "        # Initializes hidden state\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of RNN\n",
        "\n",
        "        # if using the LSTM, we need a tuple of hidden states but for RNN and GRU we need only one\n",
        "        # h0 = torch.zeros((self.no_layers, BATCH_SIZE, self.hidden_dim)).to(DEVICE)\n",
        "        # c0 = torch.zeros((self.no_layers, BATCH_SIZE, self.hidden_dim)).to(DEVICE)\n",
        "        # hidden = (h0, c0)\n",
        "\n",
        "        hidden = torch.zeros((self.no_layers, self.hidden_dim)).to(DEVICE)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "xdOS0X1b0_yM"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, embedding_dim, num_classes, num_layers):\n",
        "        super().__init__()\n",
        " \n",
        "        self.output_dim = num_classes\n",
        "        self.hidden_dim = hidden_dim\n",
        " \n",
        "        self.no_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "    \n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim,\n",
        "                           num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "        self.fc = nn.Linear(self.hidden_dim, num_classes)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        hidden = self.init_hidden()\n",
        "\n",
        "        embedded = self.embedding(text, offsets)\n",
        "\n",
        "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "\n",
        "        out = self.fc(out).squeeze()\n",
        "\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        return sig_out\n",
        "\n",
        "    def init_hidden(self):\n",
        "        h0 = torch.zeros((self.no_layers, self.hidden_dim)).to(DEVICE)\n",
        "        c0 = torch.zeros((self.no_layers, self.hidden_dim)).to(DEVICE)\n",
        "        hidden = (h0, c0)\n",
        "\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "HCId0FdDIiAj"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim, embedding_dim, num_classes, num_layers):\n",
        "        super().__init__()\n",
        " \n",
        "        self.output_dim = num_classes\n",
        "        self.hidden_dim = hidden_dim\n",
        " \n",
        "        self.no_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "    \n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=self.hidden_dim,\n",
        "                           num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "        self.fc = nn.Linear(self.hidden_dim, num_classes)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        hidden = self.init_hidden()\n",
        "\n",
        "        embedded = self.embedding(text, offsets)\n",
        "\n",
        "        gru_out, hidden = self.gru(embedded, hidden)\n",
        "        gru_out = gru_out.contiguous().view(-1, self.hidden_dim) \n",
        "\n",
        "        out = self.dropout(gru_out)\n",
        "\n",
        "        out = self.fc(out).squeeze()\n",
        "\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        return sig_out\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros((self.no_layers, self.hidden_dim)).to(DEVICE)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "kz4RtLltJiKq"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "criterion = torch.nn.BCELoss()\n",
        "# model = TextClassificationModel(VOCABULARY_SIZE, EMBEDDING_DIM, NUM_CLASSES).to(DEVICE)\n",
        "# model = SentimentRNN(VOCABULARY_SIZE, HIDDEN_DIM, EMBEDDING_DIM, NUM_CLASSES, NUM_LAYERS).to(DEVICE)\n",
        "# model = SentimentLSTM(VOCABULARY_SIZE, HIDDEN_DIM, EMBEDDING_DIM, NUM_CLASSES, NUM_LAYERS).to(DEVICE)\n",
        "model = SentimentGRU(VOCABULARY_SIZE, HIDDEN_DIM, EMBEDDING_DIM, NUM_CLASSES, NUM_LAYERS).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "ymwaQz9KtwXU"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    log_interval = 50\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted = model(text, offsets)\n",
        "\n",
        "        loss = criterion(predicted, label.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d} batch '\n",
        "                  '| loss {:3f}  |'.format(epoch, idx, loss,))\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted = model(text, offsets)\n",
        "            loss = criterion(predicted, label.float())\n",
        "    return loss"
      ],
      "metadata": {
        "id": "fXZCoABzty-E"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "total_accu = 0\n",
        "for epoch in tqdm(range(1, EPOCHS + 1), total=EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_loader)\n",
        "    loss = evaluate(test_loader)\n",
        "    print('-' * 60)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          '| loss {:3f} '.format(epoch, time.time() - epoch_start_time,\n",
        "                                           loss))\n",
        "    print('-' * 60)"
      ],
      "metadata": {
        "id": "HUZh2gpruaid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421,
          "referenced_widgets": [
            "df5e91da99bd43acb2cedf21af1bde1f",
            "720e041231cd4e79b682c135d1bb78c3",
            "a97789ef817241feafeac8a3281e7abd",
            "1ffd5e403db64bba9b3ea5040ea7d2c2",
            "94e98a25c585459685d2cfbcbf48d1ac",
            "70f092d554b54c54bd224a71050ad280",
            "31bfc8a3672043fbb655627e631e963b",
            "b799ff0f4a4a448b8f77a46129fa03ed",
            "8238c7ca39274b73a301e4faa5c3309f",
            "cad14b8ed4824575aa50ac984fb469fb",
            "43da76039d3b4e10888cea42c1db570d"
          ]
        },
        "outputId": "32724465-99ad-4637-f693-3e196a5806b0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df5e91da99bd43acb2cedf21af1bde1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-e5034b119c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-a45783357118>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
