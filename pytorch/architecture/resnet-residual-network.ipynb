{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nfrom torch import Tensor\n\nfrom typing import Any, List, Optional, Type, Union","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-26T18:20:56.270430Z","iopub.execute_input":"2023-08-26T18:20:56.270826Z","iopub.status.idle":"2023-08-26T18:20:56.276768Z","shell.execute_reply.started":"2023-08-26T18:20:56.270793Z","shell.execute_reply":"2023-08-26T18:20:56.275413Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# identity_downsample is a conv layer which we might need to do which depends if we need to change the input size or we change the number of channels","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:20:56.278903Z","iopub.execute_input":"2023-08-26T18:20:56.279490Z","iopub.status.idle":"2023-08-26T18:20:56.290704Z","shell.execute_reply.started":"2023-08-26T18:20:56.279454Z","shell.execute_reply":"2023-08-26T18:20:56.289780Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class _BasicBlock(nn.Module):\n    expansion: int = 1\n\n    def __init__(\n            self,\n            in_channels: int,\n            out_channels: int,\n            stride: int,\n            downsample: Optional[nn.Module] = None,\n            groups: int = 1,\n            base_channels: int = 64,\n    ) -> None:\n        super(_BasicBlock, self).__init__()\n        self.stride = stride\n        self.downsample = downsample\n        self.groups = groups\n        self.base_channels = base_channels\n\n        self.conv1 = nn.Conv2d(in_channels, out_channels, (3, 3), (stride, stride), (1, 1), bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, (3, 3), (1, 1), (1, 1), bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x: Tensor) -> Tensor:\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out = torch.add(out, identity)\n        out = self.relu(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:20:56.292206Z","iopub.execute_input":"2023-08-26T18:20:56.292790Z","iopub.status.idle":"2023-08-26T18:20:56.305679Z","shell.execute_reply.started":"2023-08-26T18:20:56.292729Z","shell.execute_reply":"2023-08-26T18:20:56.304821Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class _Bottleneck(nn.Module):\n    expansion: int = 4\n\n    def __init__(\n            self,\n            in_channels: int,\n            out_channels: int,\n            stride: int,\n            downsample: Optional[nn.Module] = None,\n            groups: int = 1,\n            base_channels: int = 64,\n    ) -> None:\n        super(_Bottleneck, self).__init__()\n        self.stride = stride\n        self.downsample = downsample\n        self.groups = groups\n        self.base_channels = base_channels\n\n        channels = int(out_channels * (base_channels / 64.0)) * groups\n\n        self.conv1 = nn.Conv2d(in_channels, channels, (1, 1), (1, 1), (0, 0), bias=False)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.conv2 = nn.Conv2d(channels, channels, (3, 3), (stride, stride), (1, 1), groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.conv3 = nn.Conv2d(channels, int(out_channels * self.expansion), (1, 1), (1, 1), (0, 0), bias=False)\n        self.bn3 = nn.BatchNorm2d(int(out_channels * self.expansion))\n        self.relu = nn.ReLU(True)\n\n    def forward(self, x: Tensor) -> Tensor:\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out = torch.add(out, identity)\n        out = self.relu(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:20:56.307593Z","iopub.execute_input":"2023-08-26T18:20:56.308272Z","iopub.status.idle":"2023-08-26T18:20:56.319781Z","shell.execute_reply.started":"2023-08-26T18:20:56.308239Z","shell.execute_reply":"2023-08-26T18:20:56.318697Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n\n    def __init__(\n            self,\n            arch_cfg: List[int],\n            block: Type[Union[_BasicBlock, _Bottleneck]],\n            image_channels: int,\n            groups: int = 1,\n            channels_per_group: int = 64,\n            num_classes: int = 1000,\n    ) -> None:\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.dilation = 1\n        self.groups = groups\n        self.base_channels = channels_per_group\n\n#         self.conv1 = nn.Conv2d(3, self.in_channels, (7, 7), (2, 2), (3, 3), bias=False)\n#         self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.conv1 = nn.Conv2d(image_channels, self.in_channels, (7, 7), (2, 2), (3, 3), bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(True)\n        self.maxpool = nn.MaxPool2d((3, 3), (2, 2), (1, 1))\n\n        self.layer1 = self._make_layer(arch_cfg[0], block, 64, 1)\n        self.layer2 = self._make_layer(arch_cfg[1], block, 128, 2)\n        self.layer3 = self._make_layer(arch_cfg[2], block, 256, 2)\n        self.layer4 = self._make_layer(arch_cfg[3], block, 512, 2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        # Initialize neural network weights\n        self._initialize_weights()\n\n    def _make_layer(\n            self,\n            repeat_times: int,\n            block: Type[Union[_BasicBlock, _Bottleneck]],\n            channels: int,\n            stride: int = 1,\n    ) -> nn.Sequential:\n        downsample = None\n\n        if stride != 1 or self.in_channels != channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, channels * block.expansion, (1, 1), (stride, stride), (0, 0), bias=False),\n                nn.BatchNorm2d(channels * block.expansion),\n            )\n\n        layers = [\n            block(\n                self.in_channels,\n                channels,\n                stride,\n                downsample,\n                self.groups,\n                self.base_channels\n            )\n        ]\n        self.in_channels = channels * block.expansion\n        for _ in range(1, repeat_times):\n            layers.append(\n                block(\n                    self.in_channels,\n                    channels,\n                    1,\n                    None,\n                    self.groups,\n                    self.base_channels,\n                )\n            )\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x: Tensor) -> Tensor:\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n\n        return out\n\n    def _initialize_weights(self) -> None:\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d):\n                nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(module.weight, 1)\n                nn.init.constant_(module.bias, 0)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:20:56.458967Z","iopub.execute_input":"2023-08-26T18:20:56.459375Z","iopub.status.idle":"2023-08-26T18:20:56.477610Z","shell.execute_reply.started":"2023-08-26T18:20:56.459340Z","shell.execute_reply":"2023-08-26T18:20:56.476244Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def resnet18(**kwargs: Any) -> ResNet:\n    model = ResNet([2, 2, 2, 2], _BasicBlock, **kwargs)\n\n    return model\n\n\ndef resnet34(**kwargs: Any) -> ResNet:\n    model = ResNet([3, 4, 6, 3], _BasicBlock, **kwargs)\n\n    return model\n\n\ndef resnet50(**kwargs: Any) -> ResNet:\n    model = ResNet([3, 4, 6, 3], _Bottleneck, **kwargs)\n\n    return model\n\n\ndef resnet101(**kwargs: Any) -> ResNet:\n    model = ResNet([3, 4, 23, 3], _Bottleneck, **kwargs)\n\n    return model\n\n\ndef resnet152(**kwargs: Any) -> ResNet:\n    model = ResNet([3, 8, 36, 3], _Bottleneck, **kwargs)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:20:56.479236Z","iopub.execute_input":"2023-08-26T18:20:56.479553Z","iopub.status.idle":"2023-08-26T18:20:56.496270Z","shell.execute_reply.started":"2023-08-26T18:20:56.479525Z","shell.execute_reply":"2023-08-26T18:20:56.495088Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def test():\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    img_chan = 3\n    \n    x = torch.randn(2, img_chan, 10, 10)\n\n    model = resnet101(image_channels = img_chan)\n    \n    y = model(x).to(DEVICE)\n    \n    print(y)\n    print(y.shape)\n    \ntest()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:23:33.636513Z","iopub.execute_input":"2023-08-26T18:23:33.636947Z","iopub.status.idle":"2023-08-26T18:23:34.491791Z","shell.execute_reply.started":"2023-08-26T18:23:33.636908Z","shell.execute_reply":"2023-08-26T18:23:34.490684Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tensor([[ 3.7402e-01, -3.1681e-01,  1.5058e-01,  ...,  1.2369e+00,\n          2.3088e-01, -7.2867e-01],\n        [ 8.6498e-01, -1.2532e-02,  3.2819e-01,  ..., -3.8343e-01,\n         -5.9068e-05,  4.4210e-01]], grad_fn=<AddmmBackward0>)\ntorch.Size([2, 1000])\n","output_type":"stream"}]}]}